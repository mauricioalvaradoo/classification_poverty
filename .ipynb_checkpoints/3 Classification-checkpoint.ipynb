{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e64044-3e89-4a83-bc31-71165728e307",
   "metadata": {},
   "source": [
    "# Clasificación de personas en situación de pobreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46ad7d1-4416-4335-a4ce-7fcf52e71f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Clasificadores\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7388b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>hombre</th>\n",
       "      <th>est_sup</th>\n",
       "      <th>colegio_priv</th>\n",
       "      <th>gran_empresa</th>\n",
       "      <th>segundo_trab</th>\n",
       "      <th>ingbrut</th>\n",
       "      <th>urbano</th>\n",
       "      <th>no_pobre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1454.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1842.066732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad  hombre  est_sup  colegio_priv  gran_empresa  segundo_trab  \\\n",
       "1  28.0     0.0      1.0           0.0           0.0           1.0   \n",
       "2  48.0     0.0      0.0           0.0           0.0           1.0   \n",
       "3  25.0     0.0      0.0           0.0           0.0           0.0   \n",
       "4  16.0     0.0      0.0           0.0           0.0           0.0   \n",
       "6  41.0     0.0      0.0           0.0           0.0           1.0   \n",
       "\n",
       "       ingbrut  urbano  no_pobre  \n",
       "1  1454.500000     1.0       1.0  \n",
       "2  2037.000000     1.0       1.0  \n",
       "3  2037.000000     1.0       1.0  \n",
       "4  2037.000000     1.0       1.0  \n",
       "6  1842.066732     1.0       1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta = pd.read_csv(\"./data/data_f.csv\", index_col=0)\n",
    "dta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe11732-a7f3-4c81-866b-30a5c6e0dd8b",
   "metadata": {},
   "source": [
    "## Split y estandarización\n",
    "Primero definimos las variables que tendremos como explicativas y al target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37f3acd-fd12-4177-b061-991b84c494cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = dta.loc[(dta[\"ingbrut\"] > 0)]\n",
    "dta[\"lning\"] = np.log(dta[\"ingbrut\"])\n",
    "X_names = [\"edad\", \"hombre\", \"est_sup\", \"colegio_priv\", \"gran_empresa\", \"segundo_trab\", \"urbano\", \"lning\"]\n",
    "X = dta[X_names]\n",
    "y = dta[\"no_pobre\"]\n",
    "\n",
    "# Estandarización\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22668d6-39fc-4170-8ec4-cd65aea31a41",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567dca8-7965-492b-994f-a506246e4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La distribución de la variable `no pobre` es:\\n{y.value_counts()}\\n\")\n",
    "print(f\"La distribución de la variable `no pobre` de entrenamiento es:\\n{y_train.value_counts()}\\n\")\n",
    "print(f\"La distribución de la variable `no pobre` de testing es:\\n{y_test.value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b07e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "correl = pd.DataFrame(X, columns=X_names).corr()\n",
    "\n",
    "sns.heatmap(correl, annot=True, fmt = \".1f\", cmap=\"RdPu\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title(\"Correlación entre explicativas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c4cd3-b853-45a3-9a5d-d645869ddec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), tight_layout=True)\n",
    "\n",
    "axes[0].hist(dta[\"edad\"], bins=20, density=True)\n",
    "axes[1].hist(dta[\"lning\"], bins=50, density=True)\n",
    "\n",
    "fig.suptitle(\"Distribuciones de las edades y del logaritmo de los ingresos\")\n",
    "\n",
    "plt.savefig(\"./figures/distribuciones.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877e954-0e20-4147-ab05-5c8e0ca2bbe3",
   "metadata": {},
   "source": [
    "## Relaciones entre las variables\n",
    "Para poder encontrar relaciones entre las variables, debido a que los modelos de clasificación no necesariante tienen ese objetivo. se puede estimar un modelo Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff9f25-cf58-4451-9d0c-fc4b533504df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050306c-6a20-42b5-a5ef-9fff36055c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AME = results.get_margeff(at=\"overall\", method=\"dydx\")\n",
    "\n",
    "print(AME.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10bbff-32de-484c-bea2-d619b52cd5bf",
   "metadata": {},
   "source": [
    "Los resultados son interesantes:\n",
    "\n",
    "* Las personas con mayor edad tienen menos probabilidad de ser probreza\n",
    "* El ser hombre no reduce el nivel de pobreza, sino lo vuelve mas probable\n",
    "* Tener un estudio superior (no universitario, universitario, maestria o doctorado) reduce los niveles de pobreza\n",
    "* Haber estudiado en un colegio privado reduce la probabilidad de ser pobre\n",
    "* Vivir en una zona urbana tambien reduce la probabilidad de ser pobre\n",
    "* _El mas evidente_: recibir mayores ingresos tambien reduce la probabilidad de ser pobre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899899a0-f526-48d9-88d8-ac2a75107e13",
   "metadata": {},
   "source": [
    "## Algoritmos\n",
    "Se estimaron 9 algoritmos. Aquellos que dependen de los valores iniciales, se fijó un seed. Se usó cross-validation con Grid Search para conseguir el mejor modelo posible para cada algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dcc0dd-0287-41ec-8739-3e5aa09aed24",
   "metadata": {},
   "source": [
    "### Modelo 1: Modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf7c71-e4a3-4cd8-9c71-09ca9dd21549",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "yhat_proba_ml = ml.predict(X_test)\n",
    "yhat_ml = (yhat_proba_ml >= 0.5).astype(int)\n",
    "\n",
    "# Estadisticos\n",
    "score_ml = accuracy_score(y_test, yhat_ml)\n",
    "ps_ml = precision_score(y_test, yhat_ml)\n",
    "r_ml = recall_score(y_test, yhat_ml)\n",
    "f1_ml = f1_score(y_test, yhat_ml)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_ml = confusion_matrix(y_test, yhat_ml, normalize=\"true\")\n",
    "report_ml = classification_report(y_test, yhat_ml)\n",
    "fml, tml, thresholds = roc_curve(y_test, yhat_proba_ml)\n",
    "\n",
    "print(report_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238a174-b938-4b2d-b33a-77a59ad950b2",
   "metadata": {},
   "source": [
    "### Modelo 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f32265-d97d-4202-8eee-c66bb3685c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=19).fit(X_train, y_train)\n",
    "\n",
    "yhat_proba_lr = lr.predict_proba(X_test)[:,1]\n",
    "yhat_lr = lr.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_lr = accuracy_score(y_test, yhat_lr)\n",
    "ps_lr = precision_score(y_test, yhat_lr)\n",
    "r_lr = recall_score(y_test, yhat_lr)\n",
    "f1_lr = f1_score(y_test, yhat_lr)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_lr = confusion_matrix(y_test, yhat_lr, normalize=\"true\")\n",
    "report_lr = classification_report(y_test, yhat_lr)\n",
    "flr, tlr, thresholds = roc_curve(y_test, yhat_proba_lr)\n",
    "\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2441d9-54c0-4704-a9fe-649e4fcc9aeb",
   "metadata": {},
   "source": [
    "### Modelo 3. K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1d28a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid Search: Cantidad de Neigbours\n",
    "knn_grid_search = KNeighborsClassifier()\n",
    "k_range = list(range(1, 26))\n",
    "param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'weights': [\"uniform\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    knn_grid_search, param_grid, cv = 5, scoring = \"accuracy\",\n",
    "    verbose = 10,  n_jobs = -1 # Paralelización\n",
    ")\n",
    "\n",
    "knn = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.best_params_)\n",
    "print(knn.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9270ae5-3891-4444-a526-5d4e9aa55630",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_proba_knn = knn.predict_proba(X_test)[:,1]\n",
    "yhat_knn = knn.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_knn = accuracy_score(y_test, yhat_knn)\n",
    "ps_knn = precision_score(y_test, yhat_knn)\n",
    "r_knn = recall_score(y_test, yhat_knn)\n",
    "f1_knn = f1_score(y_test, yhat_knn)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_knn = confusion_matrix(y_test, yhat_knn, normalize=\"true\")\n",
    "report_knn = classification_report(y_test, yhat_knn)\n",
    "fknn, tknn, thresholds = roc_curve(y_test, yhat_proba_knn)\n",
    "\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af80ad-b058-47f2-aa4d-7714d24cfe5d",
   "metadata": {},
   "source": [
    "### Modelo 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fbbbe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Grid Search: Cantidad de Ramas\n",
    "tree_grid_search = DecisionTreeClassifier()\n",
    "max_depth_range = list(range(1, 11))\n",
    "param_grid = {\n",
    "    'criterion' : [\"entropy\"],\n",
    "    'max_depth' : max_depth_range,\n",
    "    'random_state': [19]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    tree_grid_search, param_grid, cv = 5, scoring = \"accuracy\",\n",
    "    verbose = 5, n_jobs = -1\n",
    ")\n",
    "\n",
    "tree = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.best_params_)\n",
    "print(tree.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3f0ad-994d-4f5b-be5b-d571703135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_proba_tree = tree.predict_proba(X_test)[:,1]\n",
    "yhat_tree = tree.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_tree = accuracy_score(y_test, yhat_tree)\n",
    "ps_tree = precision_score(y_test, yhat_tree)\n",
    "r_tree = recall_score(y_test, yhat_tree)\n",
    "f1_tree = f1_score(y_test, yhat_tree)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_tree = confusion_matrix(y_test, yhat_tree, normalize=\"true\")\n",
    "report_tree = classification_report(y_test, yhat_tree)\n",
    "ftree, ttree, thresholds = roc_curve(y_test, yhat_proba_tree)\n",
    "\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67746382-b582-4c54-a575-6961430ae36b",
   "metadata": {},
   "source": [
    "### Modelo 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo los hyperparameters\n",
    "rf_grid_search = RandomForestClassifier()\n",
    "rf_grid_search.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ce3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search: Cantidad de Ramas y Árboles\n",
    "rf_grid_search = RandomForestClassifier()\n",
    "max_depth_range = list(range(1, 11))\n",
    "n_estimators_range = [100, 200, 300, 400, 500]\n",
    "\n",
    "param_grid = {\n",
    "    'criterion' : [\"entropy\"],\n",
    "    'max_depth': max_depth_range,       # Máxima profundidad\n",
    "    'n_estimators': n_estimators_range, # Número de arboles\n",
    "    'random_state': [19]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf_grid_search, param_grid, cv = 5, scoring = \"accuracy\",\n",
    "    verbose = 1, n_jobs = -1\n",
    ")\n",
    "\n",
    "rf = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.best_params_)\n",
    "print(rf.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20028c82-66e2-4368-89c1-d511ec169305",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "yhat_rf = rf.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_rf = accuracy_score(y_test, yhat_rf)\n",
    "ps_rf = precision_score(y_test, yhat_rf)\n",
    "r_rf = recall_score(y_test, yhat_rf)\n",
    "f1_rf = f1_score(y_test, yhat_rf)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_rf = confusion_matrix(y_test, yhat_rf, normalize=\"true\")\n",
    "report_rf = classification_report(y_test, yhat_rf)\n",
    "frf, trf, thresholds = roc_curve(y_test, yhat_proba_rf)\n",
    "\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55aa53-8c45-4541-967e-6cf0b92fd91c",
   "metadata": {},
   "source": [
    "### Modelo 6. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a234bc2-29ef-4f7f-8a47-93f2d9fcae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(19)\n",
    "\n",
    "nn = Sequential(\n",
    "    [\n",
    "        Input(shape = (8,)),\n",
    "        Dense(units = 32, activation = \"sigmoid\", name = \"Layer1\"),\n",
    "        Dense(units = 16, activation = \"sigmoid\", name = \"Layer2\"),\n",
    "        Dense(units = 8, activation = \"sigmoid\", name = \"Layer3\"),\n",
    "        Dense(units = 1, activation = \"sigmoid\", name = \"Layer4\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "nn.compile(\n",
    "    loss = BinaryCrossentropy(),\n",
    "    optimizer = Adam(0.001)\n",
    ")\n",
    "\n",
    "results = nn.fit(X_train, y_train, epochs = 50, verbose = False)\n",
    "\n",
    "yhat_proba_nn = nn.predict(X_test)\n",
    "yhat_nn = (yhat_proba_nn >= .5).astype(int)\n",
    "\n",
    "# Estadisticos\n",
    "score_nn = accuracy_score(y_test, yhat_nn)\n",
    "ps_nn = precision_score(y_test, yhat_nn)\n",
    "r_nn = recall_score(y_test, yhat_nn)\n",
    "f1_nn = f1_score(y_test, yhat_nn)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_nn = confusion_matrix(y_test, yhat_nn, normalize=\"true\")\n",
    "report_nn = classification_report(y_test, yhat_nn)\n",
    "fnn, tnn, thresholds = roc_curve(y_test, yhat_proba_nn)\n",
    "\n",
    "print(report_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f36c8c-5729-4e73-a5f8-a70b4e40961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(results.history[\"loss\"], color=\"black\")\n",
    "\n",
    "plt.title(\"Función de pérdida para cada iteración\", fontsize = 10)\n",
    "\n",
    "plt.savefig(\"./figures/loss-function.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f71b6f",
   "metadata": {},
   "source": [
    "### Modelo 7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search:\n",
    "svm_grid_search = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1],\n",
    "    'kernel': ['rbf'],\n",
    "    'probability': [True], # Para predict_proba\n",
    "    'random_state': [19]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    svm_grid_search, param_grid, cv = 5, scoring = \"accuracy\",\n",
    "    verbose = 3, n_jobs = -1\n",
    ")\n",
    "\n",
    "svm = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm.best_params_)\n",
    "print(svm.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_proba_svm = svm.predict_proba(X_test)[:,1]\n",
    "yhat_svm = svm.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_svm = accuracy_score(y_test, yhat_svm)\n",
    "ps_svm = precision_score(y_test, yhat_svm)\n",
    "r_svm = recall_score(y_test, yhat_svm)\n",
    "f1_svm = f1_score(y_test, yhat_svm)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_svm = confusion_matrix(y_test, yhat_svm, normalize=\"true\")\n",
    "report_svm = classification_report(y_test, yhat_svm)\n",
    "fsvm, tsvm, thresholds = roc_curve(y_test, yhat_proba_svm)\n",
    "\n",
    "print(report_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7292898",
   "metadata": {},
   "source": [
    "### Modelo 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ca38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric = \"mlogloss\", random_state = 19).fit(X_train, y_train)\n",
    "\n",
    "yhat_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "yhat_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_xgb = accuracy_score(y_test, yhat_xgb)\n",
    "ps_xgb = precision_score(y_test, yhat_xgb)\n",
    "r_xgb = recall_score(y_test, yhat_xgb)\n",
    "f1_xgb = f1_score(y_test, yhat_xgb)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_xgb = confusion_matrix(y_test, yhat_xgb, normalize=\"true\")\n",
    "report_xgb = classification_report(y_test, yhat_xgb)\n",
    "fxgb, txgb, thresholds = roc_curve(y_test, yhat_proba_xgb)\n",
    "\n",
    "print(report_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306ce8a",
   "metadata": {},
   "source": [
    "### Modelo 9. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80257750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter random_state for estimator GaussianNB(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\m_alv\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 245, in set_params\n    raise ValueError(\nValueError: Invalid parameter random_state for estimator GaussianNB(). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_smoothing\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m19\u001b[39m]\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m      9\u001b[0m     nb_grid_search, param_grid, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     10\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter random_state for estimator GaussianNB(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "nb_grid_search = GaussianNB()\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100),\n",
    "    'random_state': [19]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    nb_grid_search, param_grid, cv = 5, scoring = \"accuracy\", \n",
    "    verbose = 10, n_jobs = -1\n",
    ")\n",
    "\n",
    "nb = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa12179",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb.best_params_)\n",
    "print(nb.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_proba_nb = nb.predict_proba(X_test)[:,1]\n",
    "yhat_nb = nb.predict(X_test)\n",
    "\n",
    "# Estadisticos\n",
    "score_nb = accuracy_score(y_test, yhat_nb)\n",
    "ps_nb = precision_score(y_test, yhat_nb)\n",
    "r_nb = recall_score(y_test, yhat_nb)\n",
    "f1_nb = f1_score(y_test, yhat_nb)\n",
    "\n",
    "# Confusion matrix y ROC\n",
    "conf_nb = confusion_matrix(y_test, yhat_nb, normalize=\"true\")\n",
    "report_nb = classification_report(y_test, yhat_nb)\n",
    "fnb, tnb, thresholds = roc_curve(y_test, yhat_proba_nb)\n",
    "\n",
    "print(report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dfd0c2-09d4-412b-b361-384f21d54d27",
   "metadata": {},
   "source": [
    "### Comparativa entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638e818-3071-4fb3-9d12-4e038fc7b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Indicadores de ajuste en testing\n",
    "dict_ajust = {\n",
    "    \"Regresión lineal\": score_ml,\n",
    "    \"Regresión logistica\": score_lr,\n",
    "    \"KNN\": score_knn,\n",
    "    \"Decision tree\": score_tree,\n",
    "    \"Random forest\": score_rf,\n",
    "    \"Neural networks\": score_nn,\n",
    "    \"SVM\": score_svm,\n",
    "    \"XGBoost\": score_xgb,\n",
    "    \"Naive Bayes\": score_nb\n",
    "}\n",
    "\n",
    "df_score = pd.DataFrame(dict_ajust.items(), columns=[\"Modelo\", \"Score\"]).set_index(\"Modelo\")\n",
    "df_score[\"Score\"] = np.round(df_score[\"Score\"], 3)\n",
    "df_score = df_score.sort_values(\"Score\", ascending=False)\n",
    "\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1ff5d-ace9-47cc-afe6-a7f75230a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = utils.render_mpl_table(df_score.reset_index(), header_columns=0, col_width=2.0)\n",
    "fig.savefig(\"./figures/score.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178eb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Precision\n",
    "dict_precision = {\n",
    "    \"Regresión lineal\": ps_ml,\n",
    "    \"Regresión logistica\": ps_lr,\n",
    "    \"KNN\": ps_knn,\n",
    "    \"Decision tree\": ps_tree,\n",
    "    \"Random forest\": ps_rf,\n",
    "    \"Neural networks\": ps_nn,\n",
    "    \"SVM\": ps_svm,\n",
    "    \"XGBoost\": ps_xgb,\n",
    "    \"Naive Bayes\": ps_nb\n",
    "}\n",
    "\n",
    "df_precision = pd.DataFrame(dict_precision.items(), columns=[\"Modelo\", \"Precision\"]).set_index(\"Modelo\")\n",
    "df_precision[\"Precision\"] = np.round(df_precision[\"Precision\"], 3)\n",
    "df_precision = df_precision.sort_values(\"Precision\", ascending=False)\n",
    "\n",
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Recall\n",
    "dict_recall = {\n",
    "    \"Regresión lineal\": r_ml,\n",
    "    \"Regresión logistica\": r_lr,\n",
    "    \"KNN\": r_knn,\n",
    "    \"Decision tree\": r_tree,\n",
    "    \"Random forest\": r_rf,\n",
    "    \"Neural networks\": r_nn,\n",
    "    \"SVM\": r_svm,\n",
    "    \"XGBoost\": r_xgb,\n",
    "    \"Naive Bayes\": r_nb\n",
    "}\n",
    "\n",
    "df_recall = pd.DataFrame(dict_recall.items(), columns=[\"Modelo\", \"Recall\"]).set_index(\"Modelo\")\n",
    "df_recall[\"Recall\"] = np.round(df_recall[\"Recall\"], 3)\n",
    "df_recall = df_recall.sort_values(\"Recall\", ascending=False)\n",
    "\n",
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fc42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. F1-Score\n",
    "dict_f1 = {\n",
    "    \"Regresión lineal\": f1_ml,\n",
    "    \"Regresión logistica\": f1_lr,\n",
    "    \"KNN\": f1_knn,\n",
    "    \"Decision tree\": f1_tree,\n",
    "    \"Random forest\": f1_rf,\n",
    "    \"Neural networks\": f1_nn,\n",
    "    \"SVM\": f1_svm,\n",
    "    \"XGBoost\": f1_xgb,\n",
    "    \"Naive Bayes\": f1_nb\n",
    "}\n",
    "\n",
    "df_f1 = pd.DataFrame(dict_f1.items(), columns=[\"Modelo\", \"F1-Score\"]).set_index(\"Modelo\")\n",
    "df_f1[\"F1-Score\"] = np.round(df_f1[\"F1-Score\"], 3)\n",
    "df_f1 = df_f1.sort_values(\"F1-Score\", ascending=False)\n",
    "\n",
    "df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82949e9-e7f6-4d70-9d96-0b798ab63355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Matriz de confusion\n",
    "dict_conf = {\n",
    "    \"Regresión lineal\": conf_ml,\n",
    "    \"Regresión logistica\": conf_lr,\n",
    "    \"KNN\": conf_knn,\n",
    "    \"Decision tree\": conf_tree,\n",
    "    \"Random forest\": conf_rf,\n",
    "    \"Neural networks\": conf_nn,\n",
    "    \"SVM\": conf_svm,\n",
    "    \"XGBoost\": conf_xgb,\n",
    "    \"Naive Bayes\": conf_nb\n",
    "}\n",
    "\n",
    "conf_names = list(dict_conf.keys())\n",
    "conf_matrixes = dict_conf.values()\n",
    "\n",
    "\n",
    "# Figura\n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "r = 0; c = 0; i = 0\n",
    "\n",
    "for matrix in conf_matrixes:\n",
    "    fig = ConfusionMatrixDisplay(\n",
    "        confusion_matrix = matrix,\n",
    "    ).plot(ax = ax[r, c], colorbar = False, cmap=plt.cm.Blues)\n",
    "    \n",
    "    ax[r, c].set_title(conf_names[i])\n",
    "    ax[r, c].set_xlabel(\"Predicción\")\n",
    "    ax[r, c].set_ylabel(\"Real\")\n",
    "    \n",
    "    i += 1\n",
    "    r += 1\n",
    "    if r == 3:\n",
    "        c += 1\n",
    "        r = 0\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "plt.suptitle(\"Matrices de confusión (normalizadas a los valores reales)\")\n",
    "plt.subplots_adjust(top=0.9, bottom=0.4, left=0.2, right=0.75, hspace=0.6, wspace=0.5)\n",
    "\n",
    "plt.savefig(\"./figures/matrices_confusion.pdf\", bbox_inches=\"tight\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c4714-c6f0-4289-a0f5-16df7bfa0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ROC\n",
    "dict_conf = {\n",
    "    \"Regresión lineal\": [fml, tml],\n",
    "    \"Regresión logistica\": [flr, tlr],\n",
    "    \"KNN\": [fknn, tknn],\n",
    "    \"Decision tree\": [ftree, ttree],\n",
    "    \"Random forest\": [frf, trf],\n",
    "    \"Neural networks\": [fnn, tnn],\n",
    "    \"SVM\": [fsvm, tsvm],\n",
    "    \"XGBoost\": [fxgb, txgb],\n",
    "    \"Naive Bayes\": [fnb, tnb]\n",
    "}\n",
    "keys = list(dict_conf.keys())\n",
    "values = list(dict_conf.values())\n",
    "\n",
    "\n",
    "# Figura\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"(ROC = 0.5)\")\n",
    "\n",
    "j = 0\n",
    "for i in values:\n",
    "    plt.plot(i[0], i[1], label=keys[j])\n",
    "    j += 1\n",
    "\n",
    "plt.xlabel(\"Ratio falso positivo\")\n",
    "plt.ylabel(\"Ratio verdadero positivo\")\n",
    "plt.title(\"Curvas ROC\")\n",
    "plt.legend(fontsize=9)\n",
    "\n",
    "plt.savefig(\"./figures/roc.pdf\", bbox_inches=\"tight\", transparent=True)\n",
    "plt.savefig(\"./figures/roc.png\", bbox_inches=\"tight\", transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
